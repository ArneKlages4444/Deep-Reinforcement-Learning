{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoOEob3gB00H",
        "outputId": "7f0d9749-38bc-4743-f5f0-69c9f7572bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gym 0.25.2\n",
            "Uninstalling gym-0.25.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/gym-0.25.2.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/gym/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled gym-0.25.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 uninstall gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym[mujoco]\n",
            "  Downloading gym-0.26.1.tar.gz (719 kB)\n",
            "\u001b[K     |████████████████████████████████| 719 kB 4.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[mujoco]) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[mujoco]) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[mujoco]) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[mujoco]) (1.5.0)\n",
            "Collecting mujoco==2.2.0\n",
            "  Downloading mujoco-2.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 42.9 MB/s \n",
            "\u001b[?25hCollecting imageio>=2.14.1\n",
            "  Downloading imageio-2.22.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 43.1 MB/s \n",
            "\u001b[?25hCollecting glfw\n",
            "  Downloading glfw-2.5.5-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mujoco==2.2.0->gym[mujoco]) (1.2.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.7/dist-packages (from mujoco==2.2.0->gym[mujoco]) (3.1.6)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[mujoco]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[mujoco]) (4.1.1)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.1-py3-none-any.whl size=826212 sha256=78760047627ff804899d9407e747805b6880c6a342e20c1b72ae92cf878a2464\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/f0/10/6f06af57d047770ee4b45f9408dbb90bb55916892e8e9fbc86\n",
            "Successfully built gym\n",
            "Installing collected packages: pillow, glfw, mujoco, imageio, gym\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed glfw-2.5.5 gym-0.26.1 imageio-2.22.0 mujoco-2.2.0 pillow-9.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip3 install gym[mujoco]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "b9hF7N706aXK",
        "outputId": "7c27c0a9-2b90-4fd0-c72c-de3b913aebb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ExperienceReplayBuffer:\n",
        "    def __init__(self, state_dims, action_dims, max_size=1000000, batch_size=256):\n",
        "        self._max_size = max_size\n",
        "        self._batch_size = batch_size\n",
        "        self._size = 0\n",
        "        self._current_position = 0\n",
        "        self._state_memory = np.zeros((self._max_size, *state_dims))\n",
        "        self._state_prime_memory = np.zeros((self._max_size, *state_dims))\n",
        "        self._action_memory = np.zeros((self._max_size, action_dims))\n",
        "        self._reward_memory = np.zeros((self._max_size, 1))\n",
        "        self._done_memory = np.zeros((self._max_size, 1), dtype=np.bool)\n",
        "\n",
        "    def size(self):\n",
        "        return self._size\n",
        "\n",
        "    def add_transition(self, state, action, reward, state_, done):\n",
        "        self._state_memory[self._current_position] = state\n",
        "        self._state_prime_memory[self._current_position] = state_\n",
        "        self._action_memory[self._current_position] = action\n",
        "        self._reward_memory[self._current_position] = reward\n",
        "        self._done_memory[self._current_position] = done\n",
        "        # self.un_norm_r[self.current_position] = r\n",
        "        # self.r = (self.un_norm_r - np.mean(self.un_norm_r)) / (np.std(self.un_norm_r) + 1e-10)\n",
        "        if self._size < self._max_size:\n",
        "            self._size += 1\n",
        "        self._current_position = (self._current_position + 1) % self._max_size\n",
        "\n",
        "    def sample_batch(self):\n",
        "        batch_indices = np.random.choice(self._size, self._batch_size, replace=False)\n",
        "        states = tf.convert_to_tensor(self._state_memory[batch_indices], dtype=tf.float32)\n",
        "        states_prime = tf.convert_to_tensor(self._state_prime_memory[batch_indices], dtype=tf.float32)\n",
        "        actions = tf.convert_to_tensor(self._action_memory[batch_indices], dtype=tf.float32)\n",
        "        rewards = tf.convert_to_tensor(self._reward_memory[batch_indices], dtype=tf.float32)\n",
        "        dones = tf.convert_to_tensor(self._done_memory[batch_indices], dtype=tf.float32)\n",
        "        return states, actions, rewards, states_prime, dones\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Concatenate\n",
        "\n",
        "\n",
        "def create_policy_network(learning_rate, state_dim, action_dim):\n",
        "    inputs = keras.Input(shape=state_dim)\n",
        "    x = Dense(256, activation=tf.nn.relu)(inputs)\n",
        "    x = Dense(256, activation=tf.nn.relu)(x)\n",
        "    x = Dense(256, activation=tf.nn.relu)(x)\n",
        "    out = Dense(action_dim, activation=tf.nn.tanh)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=out)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate))\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_q_network(learning_rate, state_dim, action_dim):\n",
        "    inputs_s = keras.Input(shape=state_dim)\n",
        "    inputs_a = keras.Input(shape=action_dim)\n",
        "    x = Concatenate()([inputs_s, inputs_a])\n",
        "    x = Dense(256, activation=tf.nn.relu)(x)\n",
        "    x = Dense(256, activation=tf.nn.relu)(x)\n",
        "    x = Dense(256, activation=tf.nn.relu)(x)\n",
        "    out = Dense(1, activation=None)(x)\n",
        "    model = keras.Model(inputs=(inputs_s, inputs_a), outputs=out)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate))\n",
        "    return model\n",
        "\n",
        "\n",
        "# from ExperienceReplayBuffer import ExperienceReplayBuffer\n",
        "import tensorflow as tf\n",
        "from tensorflow import math as tfm\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# input should be between (−1, 1)\n",
        "def default_scaling(actions):\n",
        "    return actions\n",
        "\n",
        "\n",
        "# input should be between (−1, 1)\n",
        "def multiplicative_scaling(actions, factors):\n",
        "    return actions * factors\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, environment, state_dim, action_dim,\n",
        "                 actor_network_generator, critic_network_generator, action_scaling=default_scaling,\n",
        "                 learning_rate=0.0003, gamma=0.99, tau=0.005, policy_delay=2,\n",
        "                 target_noise=0.1, exploration_noise=0.2, noise_clip=0.5, a_low=-1, a_high=1,\n",
        "                 batch_size=256, max_replay_buffer_size=1000000):\n",
        "        self._environment = environment\n",
        "        self._action_dim = action_dim\n",
        "        self._action_scaling = action_scaling\n",
        "        self._gamma = gamma\n",
        "        self._tau = tau\n",
        "        self._policy_delay = policy_delay\n",
        "        self._target_noise = target_noise\n",
        "        self._exploration_noise = exploration_noise\n",
        "        self._noise_clip = noise_clip\n",
        "        self._a_low = a_low\n",
        "        self._a_high = a_high\n",
        "        self._batch_size = batch_size\n",
        "        self._mse = tf.keras.losses.MeanSquaredError()\n",
        "        self._reply_buffer = ExperienceReplayBuffer(state_dim, action_dim, max_replay_buffer_size, batch_size)\n",
        "        self._actor = actor_network_generator(learning_rate)\n",
        "        self._actor_t = actor_network_generator(learning_rate)\n",
        "        self._critic_1 = critic_network_generator(learning_rate)\n",
        "        self._critic_2 = critic_network_generator(learning_rate)\n",
        "        self._critic_1_t = critic_network_generator(learning_rate)\n",
        "        self._critic_2_t = critic_network_generator(learning_rate)\n",
        "        self._wight_init()\n",
        "        self.step_counter = 0\n",
        "\n",
        "    def reply_buffer(self):\n",
        "        return self._reply_buffer\n",
        "\n",
        "    def environment(self):\n",
        "        return self._environment\n",
        "\n",
        "    def _wight_init(self):\n",
        "        self._actor.set_weights(self._actor_t.weights)\n",
        "        self._critic_1.set_weights(self._critic_1_t.weights)\n",
        "        self._critic_2.set_weights(self._critic_2_t.weights)\n",
        "\n",
        "    def update_target_weights(self):\n",
        "        self._weight_update(self._actor_t, self._actor)\n",
        "        self._weight_update(self._critic_1_t, self._critic_1)\n",
        "        self._weight_update(self._critic_2_t, self._critic_2)\n",
        "\n",
        "    def _weight_update(self, target_network, network):\n",
        "        new_wights = []\n",
        "        for w_t, w in zip(target_network.weights, network.weights):\n",
        "            new_wights.append((1 - self._tau) * w_t + self._tau * w)\n",
        "        target_network.set_weights(new_wights)\n",
        "\n",
        "    def learn(self):\n",
        "        states, actions, rewards, states_prime, dones = self._reply_buffer.sample_batch()\n",
        "        self.train_step_critic(states, actions, rewards, states_prime, dones)\n",
        "        if self.step_counter % self._policy_delay:\n",
        "            self.train_step_actor(states)\n",
        "            self.update_target_weights()\n",
        "        self.step_counter += 1\n",
        "\n",
        "    @tf.function\n",
        "    def train_step_critic(self, states, actions, rewards, states_prime, dones):\n",
        "        actions_prime = self.sample_actions_form_target_policy(states_prime)\n",
        "        q1 = self._critic_1_t((states_prime, actions_prime))\n",
        "        q2 = self._critic_2_t((states_prime, actions_prime))\n",
        "        targets = rewards + self._gamma * (1 - dones) * tfm.minimum(q1, q2)\n",
        "        self._critic_update(self._critic_1, states, actions, targets)\n",
        "        self._critic_update(self._critic_2, states, actions, targets)\n",
        "\n",
        "    def _critic_update(self, critic, states, actions, targets):\n",
        "        with tf.GradientTape() as tape:\n",
        "            q = critic((states, actions))\n",
        "            loss = 0.5 * self._mse(targets, q)\n",
        "        gradients = tape.gradient(loss, critic.trainable_variables)\n",
        "        critic.optimizer.apply_gradients(zip(gradients, critic.trainable_variables))\n",
        "\n",
        "    @tf.function\n",
        "    def train_step_actor(self, states):\n",
        "        with tf.GradientTape() as tape:\n",
        "            actions_new = self._actor(states)\n",
        "            q1 = self._critic_1((states, actions_new))\n",
        "            q2 = self._critic_2((states, actions_new))\n",
        "            loss = -tfm.reduce_mean(tfm.minimum(q1, q2))\n",
        "        gradients = tape.gradient(loss, self._actor.trainable_variables)\n",
        "        self._actor.optimizer.apply_gradients(zip(gradients, self._actor.trainable_variables))\n",
        "\n",
        "    def _action_clipping(self, actions):\n",
        "        return tf.clip_by_value(actions, self._a_low, self._a_high)\n",
        "\n",
        "    def sample_actions_form_policy(self, state):\n",
        "        actions = self._actor(state)\n",
        "        # or noise from sampling form tfp normal distribution with a sigma vector to get different noise per action\n",
        "        noise = tf.random.normal(actions.get_shape(), 0, self._exploration_noise)\n",
        "        clip_actions = self._action_clipping(actions + noise)\n",
        "        return clip_actions\n",
        "\n",
        "    def sample_actions_form_target_policy(self, state):\n",
        "        actions = self._actor_t(state)\n",
        "        # or noise from sampling form tfp normal distribution with a sigma vector to get different noise per action\n",
        "        noise = tf.clip_by_value(tf.random.normal(actions.get_shape(), 0, self._target_noise),\n",
        "                                 -self._noise_clip, self._noise_clip)\n",
        "        clip_actions = self._action_clipping(actions + noise)\n",
        "        return clip_actions\n",
        "\n",
        "    def act_deterministic(self, state):\n",
        "        actions_prime = self._actor(tf.convert_to_tensor([state], dtype=tf.float32))\n",
        "        return self._act(actions_prime)\n",
        "\n",
        "    def act_stochastic(self, state):\n",
        "        actions_prime = self.sample_actions_form_policy(tf.convert_to_tensor([state], dtype=tf.float32))\n",
        "        return self._act(actions_prime)\n",
        "\n",
        "    def _act(self, actions):\n",
        "        scaled_actions = self._action_scaling(actions)  # scaled actions from (-1, 1) according (to environment)\n",
        "        observation_prime, reward, done, _, _ = self._environment.step(scaled_actions[0])\n",
        "        return actions, observation_prime, reward, done\n",
        "\n",
        "    def train(self, epochs, environment_steps=1, training_steps=1, pre_sampling_steps=0):\n",
        "        print(f\"Random exploration for {pre_sampling_steps} steps!\")\n",
        "        observation, _ = self._environment.reset()\n",
        "        ret = 0\n",
        "        for _ in range(max(pre_sampling_steps, self._batch_size)):\n",
        "            actions = tf.random.uniform((self._action_dim,), minval=-1, maxval=1)\n",
        "            actions = self._action_scaling(actions)\n",
        "            observation_prime, reward, done, _, _ = self._environment.step(actions)\n",
        "            ret += reward\n",
        "            self._reply_buffer.add_transition(observation, actions, reward, observation_prime, done)\n",
        "            if done:\n",
        "                print(\"print\", ret)\n",
        "                ret = 0\n",
        "                observation, _ = self._environment.reset()\n",
        "            else:\n",
        "                observation = observation_prime\n",
        "        print(\"print\", ret)\n",
        "\n",
        "        print(\"start training!\")\n",
        "        returns = []\n",
        "        observation, _ = self._environment.reset()\n",
        "        done = 0\n",
        "        ret = 0\n",
        "        epoch = 0\n",
        "        steps = 0\n",
        "        while True:\n",
        "            i = 0\n",
        "            while i < environment_steps or self._reply_buffer.size() < self._batch_size:\n",
        "                if done:\n",
        "                    observation, _ = self._environment.reset()\n",
        "                    returns.append(ret)\n",
        "                    print(\"epoch:\", epoch, \"steps:\", steps, \"return:\", ret, \"avg return:\", np.average(returns[-50:]))\n",
        "                    ret = 0\n",
        "                    epoch += 1\n",
        "                    if epoch >= epochs:\n",
        "                        print(\"training finished!\")\n",
        "                        return\n",
        "                actions, observation_prime, reward, done = self.act_stochastic(observation)\n",
        "                self._reply_buffer.add_transition(observation, actions, reward, observation_prime, done)\n",
        "                observation = observation_prime\n",
        "                steps += 1\n",
        "                ret += reward\n",
        "                i += 1\n",
        "            for _ in range(training_steps):\n",
        "                self.learn()\n",
        "\n",
        "\n",
        "from functools import partial\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "\n",
        "# from GenericMLPs1D import create_policy_network, create_q_network\n",
        "# from DDPGAgent import Agent, multiplicative_scaling\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.keras.backend.clear_session()\n",
        "    env = gym.make('InvertedPendulum-v4')\n",
        "    print(\"state_dim=\", env.observation_space.shape, \"action_dim=\", env.action_space.shape[0], \"action_scaling:\",\n",
        "          env.action_space.high)\n",
        "\n",
        "    agent = Agent(environment=env, state_dim=env.observation_space.shape, action_dim=env.action_space.shape[0],\n",
        "                  action_scaling=partial(multiplicative_scaling, factors=env.action_space.high),\n",
        "                  actor_network_generator=partial(create_policy_network, state_dim=env.observation_space.shape[0],\n",
        "                                                  action_dim=env.action_space.shape[0]),\n",
        "                  critic_network_generator=partial(create_q_network, state_dim=env.observation_space.shape[0],\n",
        "                                                   action_dim=env.action_space.shape[0]))\n",
        "    agent.train(10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u3kl_SYnB-E_",
        "outputId": "1c1f72e7-f292-4452-e691-f094d16963b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state_dim= (4,) action_dim= 1 action_scaling: [3.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random exploration for 0 steps!\n",
            "print 4.0\n",
            "print 9.0\n",
            "print 4.0\n",
            "print 3.0\n",
            "print 5.0\n",
            "print 3.0\n",
            "print 4.0\n",
            "print 4.0\n",
            "print 15.0\n",
            "print 3.0\n",
            "print 3.0\n",
            "print 4.0\n",
            "print 3.0\n",
            "print 8.0\n",
            "print 15.0\n",
            "print 4.0\n",
            "print 4.0\n",
            "print 5.0\n",
            "print 9.0\n",
            "print 3.0\n",
            "print 5.0\n",
            "print 4.0\n",
            "print 8.0\n",
            "print 5.0\n",
            "print 3.0\n",
            "print 6.0\n",
            "print 6.0\n",
            "print 6.0\n",
            "print 5.0\n",
            "print 4.0\n",
            "print 8.0\n",
            "print 3.0\n",
            "print 14.0\n",
            "print 4.0\n",
            "print 5.0\n",
            "print 3.0\n",
            "print 3.0\n",
            "print 4.0\n",
            "print 4.0\n",
            "print 11.0\n",
            "print 3.0\n",
            "print 3.0\n",
            "print 3.0\n",
            "print 10.0\n",
            "print 3.0\n",
            "print 3.0\n",
            "print 8.0\n",
            "start training!\n",
            "epoch: 0 steps: 27 return: 27.0 avg return: 27.0\n",
            "epoch: 1 steps: 31 return: 4.0 avg return: 15.5\n",
            "epoch: 2 steps: 35 return: 4.0 avg return: 11.666666666666666\n",
            "epoch: 3 steps: 41 return: 6.0 avg return: 10.25\n",
            "epoch: 4 steps: 44 return: 3.0 avg return: 8.8\n",
            "epoch: 5 steps: 48 return: 4.0 avg return: 8.0\n",
            "epoch: 6 steps: 52 return: 4.0 avg return: 7.428571428571429\n",
            "epoch: 7 steps: 55 return: 3.0 avg return: 6.875\n",
            "epoch: 8 steps: 58 return: 3.0 avg return: 6.444444444444445\n",
            "epoch: 9 steps: 61 return: 3.0 avg return: 6.1\n",
            "epoch: 10 steps: 64 return: 3.0 avg return: 5.818181818181818\n",
            "epoch: 11 steps: 67 return: 3.0 avg return: 5.583333333333333\n",
            "epoch: 12 steps: 70 return: 3.0 avg return: 5.384615384615385\n",
            "epoch: 13 steps: 73 return: 3.0 avg return: 5.214285714285714\n",
            "epoch: 14 steps: 76 return: 3.0 avg return: 5.066666666666666\n",
            "epoch: 15 steps: 79 return: 3.0 avg return: 4.9375\n",
            "epoch: 16 steps: 82 return: 3.0 avg return: 4.823529411764706\n",
            "epoch: 17 steps: 85 return: 3.0 avg return: 4.722222222222222\n",
            "epoch: 18 steps: 88 return: 3.0 avg return: 4.631578947368421\n",
            "epoch: 19 steps: 91 return: 3.0 avg return: 4.55\n",
            "epoch: 20 steps: 94 return: 3.0 avg return: 4.476190476190476\n",
            "epoch: 21 steps: 97 return: 3.0 avg return: 4.409090909090909\n",
            "epoch: 22 steps: 100 return: 3.0 avg return: 4.3478260869565215\n",
            "epoch: 23 steps: 103 return: 3.0 avg return: 4.291666666666667\n",
            "epoch: 24 steps: 106 return: 3.0 avg return: 4.24\n",
            "epoch: 25 steps: 109 return: 3.0 avg return: 4.1923076923076925\n",
            "epoch: 26 steps: 112 return: 3.0 avg return: 4.148148148148148\n",
            "epoch: 27 steps: 115 return: 3.0 avg return: 4.107142857142857\n",
            "epoch: 28 steps: 118 return: 3.0 avg return: 4.068965517241379\n",
            "epoch: 29 steps: 121 return: 3.0 avg return: 4.033333333333333\n",
            "epoch: 30 steps: 124 return: 3.0 avg return: 4.0\n",
            "epoch: 31 steps: 127 return: 3.0 avg return: 3.96875\n",
            "epoch: 32 steps: 130 return: 3.0 avg return: 3.9393939393939394\n",
            "epoch: 33 steps: 133 return: 3.0 avg return: 3.911764705882353\n",
            "epoch: 34 steps: 136 return: 3.0 avg return: 3.8857142857142857\n",
            "epoch: 35 steps: 139 return: 3.0 avg return: 3.861111111111111\n",
            "epoch: 36 steps: 142 return: 3.0 avg return: 3.8378378378378377\n",
            "epoch: 37 steps: 145 return: 3.0 avg return: 3.8157894736842106\n",
            "epoch: 38 steps: 148 return: 3.0 avg return: 3.7948717948717947\n",
            "epoch: 39 steps: 151 return: 3.0 avg return: 3.775\n",
            "epoch: 40 steps: 154 return: 3.0 avg return: 3.7560975609756095\n",
            "epoch: 41 steps: 157 return: 3.0 avg return: 3.738095238095238\n",
            "epoch: 42 steps: 160 return: 3.0 avg return: 3.7209302325581395\n",
            "epoch: 43 steps: 163 return: 3.0 avg return: 3.7045454545454546\n",
            "epoch: 44 steps: 166 return: 3.0 avg return: 3.688888888888889\n",
            "epoch: 45 steps: 169 return: 3.0 avg return: 3.6739130434782608\n",
            "epoch: 46 steps: 172 return: 3.0 avg return: 3.6595744680851063\n",
            "epoch: 47 steps: 175 return: 3.0 avg return: 3.6458333333333335\n",
            "epoch: 48 steps: 178 return: 3.0 avg return: 3.63265306122449\n",
            "epoch: 49 steps: 181 return: 3.0 avg return: 3.62\n",
            "epoch: 50 steps: 184 return: 3.0 avg return: 3.14\n",
            "epoch: 51 steps: 187 return: 3.0 avg return: 3.12\n",
            "epoch: 52 steps: 190 return: 3.0 avg return: 3.1\n",
            "epoch: 53 steps: 193 return: 3.0 avg return: 3.04\n",
            "epoch: 54 steps: 196 return: 3.0 avg return: 3.04\n",
            "epoch: 55 steps: 199 return: 3.0 avg return: 3.02\n",
            "epoch: 56 steps: 202 return: 3.0 avg return: 3.0\n",
            "epoch: 57 steps: 205 return: 3.0 avg return: 3.0\n",
            "epoch: 58 steps: 208 return: 3.0 avg return: 3.0\n",
            "epoch: 59 steps: 211 return: 3.0 avg return: 3.0\n",
            "epoch: 60 steps: 214 return: 3.0 avg return: 3.0\n",
            "epoch: 61 steps: 217 return: 3.0 avg return: 3.0\n",
            "epoch: 62 steps: 220 return: 3.0 avg return: 3.0\n",
            "epoch: 63 steps: 223 return: 3.0 avg return: 3.0\n",
            "epoch: 64 steps: 226 return: 3.0 avg return: 3.0\n",
            "epoch: 65 steps: 229 return: 3.0 avg return: 3.0\n",
            "epoch: 66 steps: 232 return: 3.0 avg return: 3.0\n",
            "epoch: 67 steps: 235 return: 3.0 avg return: 3.0\n",
            "epoch: 68 steps: 238 return: 3.0 avg return: 3.0\n",
            "epoch: 69 steps: 241 return: 3.0 avg return: 3.0\n",
            "epoch: 70 steps: 244 return: 3.0 avg return: 3.0\n",
            "epoch: 71 steps: 247 return: 3.0 avg return: 3.0\n",
            "epoch: 72 steps: 250 return: 3.0 avg return: 3.0\n",
            "epoch: 73 steps: 253 return: 3.0 avg return: 3.0\n",
            "epoch: 74 steps: 256 return: 3.0 avg return: 3.0\n",
            "epoch: 75 steps: 259 return: 3.0 avg return: 3.0\n",
            "epoch: 76 steps: 262 return: 3.0 avg return: 3.0\n",
            "epoch: 77 steps: 265 return: 3.0 avg return: 3.0\n",
            "epoch: 78 steps: 268 return: 3.0 avg return: 3.0\n",
            "epoch: 79 steps: 271 return: 3.0 avg return: 3.0\n",
            "epoch: 80 steps: 274 return: 3.0 avg return: 3.0\n",
            "epoch: 81 steps: 277 return: 3.0 avg return: 3.0\n",
            "epoch: 82 steps: 280 return: 3.0 avg return: 3.0\n",
            "epoch: 83 steps: 283 return: 3.0 avg return: 3.0\n",
            "epoch: 84 steps: 286 return: 3.0 avg return: 3.0\n",
            "epoch: 85 steps: 289 return: 3.0 avg return: 3.0\n",
            "epoch: 86 steps: 292 return: 3.0 avg return: 3.0\n",
            "epoch: 87 steps: 295 return: 3.0 avg return: 3.0\n",
            "epoch: 88 steps: 298 return: 3.0 avg return: 3.0\n",
            "epoch: 89 steps: 301 return: 3.0 avg return: 3.0\n",
            "epoch: 90 steps: 304 return: 3.0 avg return: 3.0\n",
            "epoch: 91 steps: 307 return: 3.0 avg return: 3.0\n",
            "epoch: 92 steps: 310 return: 3.0 avg return: 3.0\n",
            "epoch: 93 steps: 313 return: 3.0 avg return: 3.0\n",
            "epoch: 94 steps: 316 return: 3.0 avg return: 3.0\n",
            "epoch: 95 steps: 319 return: 3.0 avg return: 3.0\n",
            "epoch: 96 steps: 322 return: 3.0 avg return: 3.0\n",
            "epoch: 97 steps: 325 return: 3.0 avg return: 3.0\n",
            "epoch: 98 steps: 328 return: 3.0 avg return: 3.0\n",
            "epoch: 99 steps: 331 return: 3.0 avg return: 3.0\n",
            "epoch: 100 steps: 334 return: 3.0 avg return: 3.0\n",
            "epoch: 101 steps: 337 return: 3.0 avg return: 3.0\n",
            "epoch: 102 steps: 340 return: 3.0 avg return: 3.0\n",
            "epoch: 103 steps: 343 return: 3.0 avg return: 3.0\n",
            "epoch: 104 steps: 346 return: 3.0 avg return: 3.0\n",
            "epoch: 105 steps: 349 return: 3.0 avg return: 3.0\n",
            "epoch: 106 steps: 352 return: 3.0 avg return: 3.0\n",
            "epoch: 107 steps: 355 return: 3.0 avg return: 3.0\n",
            "epoch: 108 steps: 358 return: 3.0 avg return: 3.0\n",
            "epoch: 109 steps: 361 return: 3.0 avg return: 3.0\n",
            "epoch: 110 steps: 364 return: 3.0 avg return: 3.0\n",
            "epoch: 111 steps: 367 return: 3.0 avg return: 3.0\n",
            "epoch: 112 steps: 370 return: 3.0 avg return: 3.0\n",
            "epoch: 113 steps: 373 return: 3.0 avg return: 3.0\n",
            "epoch: 114 steps: 376 return: 3.0 avg return: 3.0\n",
            "epoch: 115 steps: 379 return: 3.0 avg return: 3.0\n",
            "epoch: 116 steps: 382 return: 3.0 avg return: 3.0\n",
            "epoch: 117 steps: 385 return: 3.0 avg return: 3.0\n",
            "epoch: 118 steps: 388 return: 3.0 avg return: 3.0\n",
            "epoch: 119 steps: 391 return: 3.0 avg return: 3.0\n",
            "epoch: 120 steps: 394 return: 3.0 avg return: 3.0\n",
            "epoch: 121 steps: 397 return: 3.0 avg return: 3.0\n",
            "epoch: 122 steps: 400 return: 3.0 avg return: 3.0\n",
            "epoch: 123 steps: 403 return: 3.0 avg return: 3.0\n",
            "epoch: 124 steps: 406 return: 3.0 avg return: 3.0\n",
            "epoch: 125 steps: 409 return: 3.0 avg return: 3.0\n",
            "epoch: 126 steps: 412 return: 3.0 avg return: 3.0\n",
            "epoch: 127 steps: 415 return: 3.0 avg return: 3.0\n",
            "epoch: 128 steps: 418 return: 3.0 avg return: 3.0\n",
            "epoch: 129 steps: 421 return: 3.0 avg return: 3.0\n",
            "epoch: 130 steps: 424 return: 3.0 avg return: 3.0\n",
            "epoch: 131 steps: 427 return: 3.0 avg return: 3.0\n",
            "epoch: 132 steps: 430 return: 3.0 avg return: 3.0\n",
            "epoch: 133 steps: 433 return: 3.0 avg return: 3.0\n",
            "epoch: 134 steps: 436 return: 3.0 avg return: 3.0\n",
            "epoch: 135 steps: 439 return: 3.0 avg return: 3.0\n",
            "epoch: 136 steps: 442 return: 3.0 avg return: 3.0\n",
            "epoch: 137 steps: 445 return: 3.0 avg return: 3.0\n",
            "epoch: 138 steps: 448 return: 3.0 avg return: 3.0\n",
            "epoch: 139 steps: 451 return: 3.0 avg return: 3.0\n",
            "epoch: 140 steps: 454 return: 3.0 avg return: 3.0\n",
            "epoch: 141 steps: 457 return: 3.0 avg return: 3.0\n",
            "epoch: 142 steps: 460 return: 3.0 avg return: 3.0\n",
            "epoch: 143 steps: 463 return: 3.0 avg return: 3.0\n",
            "epoch: 144 steps: 466 return: 3.0 avg return: 3.0\n",
            "epoch: 145 steps: 469 return: 3.0 avg return: 3.0\n",
            "epoch: 146 steps: 472 return: 3.0 avg return: 3.0\n",
            "epoch: 147 steps: 475 return: 3.0 avg return: 3.0\n",
            "epoch: 148 steps: 478 return: 3.0 avg return: 3.0\n",
            "epoch: 149 steps: 481 return: 3.0 avg return: 3.0\n",
            "epoch: 150 steps: 484 return: 3.0 avg return: 3.0\n",
            "epoch: 151 steps: 487 return: 3.0 avg return: 3.0\n",
            "epoch: 152 steps: 490 return: 3.0 avg return: 3.0\n",
            "epoch: 153 steps: 493 return: 3.0 avg return: 3.0\n",
            "epoch: 154 steps: 496 return: 3.0 avg return: 3.0\n",
            "epoch: 155 steps: 499 return: 3.0 avg return: 3.0\n",
            "epoch: 156 steps: 502 return: 3.0 avg return: 3.0\n",
            "epoch: 157 steps: 505 return: 3.0 avg return: 3.0\n",
            "epoch: 158 steps: 508 return: 3.0 avg return: 3.0\n",
            "epoch: 159 steps: 511 return: 3.0 avg return: 3.0\n",
            "epoch: 160 steps: 514 return: 3.0 avg return: 3.0\n",
            "epoch: 161 steps: 517 return: 3.0 avg return: 3.0\n",
            "epoch: 162 steps: 520 return: 3.0 avg return: 3.0\n",
            "epoch: 163 steps: 523 return: 3.0 avg return: 3.0\n",
            "epoch: 164 steps: 526 return: 3.0 avg return: 3.0\n",
            "epoch: 165 steps: 529 return: 3.0 avg return: 3.0\n",
            "epoch: 166 steps: 532 return: 3.0 avg return: 3.0\n",
            "epoch: 167 steps: 535 return: 3.0 avg return: 3.0\n",
            "epoch: 168 steps: 538 return: 3.0 avg return: 3.0\n",
            "epoch: 169 steps: 541 return: 3.0 avg return: 3.0\n",
            "epoch: 170 steps: 544 return: 3.0 avg return: 3.0\n",
            "epoch: 171 steps: 547 return: 3.0 avg return: 3.0\n",
            "epoch: 172 steps: 550 return: 3.0 avg return: 3.0\n",
            "epoch: 173 steps: 553 return: 3.0 avg return: 3.0\n",
            "epoch: 174 steps: 556 return: 3.0 avg return: 3.0\n",
            "epoch: 175 steps: 559 return: 3.0 avg return: 3.0\n",
            "epoch: 176 steps: 562 return: 3.0 avg return: 3.0\n",
            "epoch: 177 steps: 565 return: 3.0 avg return: 3.0\n",
            "epoch: 178 steps: 568 return: 3.0 avg return: 3.0\n",
            "epoch: 179 steps: 571 return: 3.0 avg return: 3.0\n",
            "epoch: 180 steps: 574 return: 3.0 avg return: 3.0\n",
            "epoch: 181 steps: 577 return: 3.0 avg return: 3.0\n",
            "epoch: 182 steps: 580 return: 3.0 avg return: 3.0\n",
            "epoch: 183 steps: 583 return: 3.0 avg return: 3.0\n",
            "epoch: 184 steps: 586 return: 3.0 avg return: 3.0\n",
            "epoch: 185 steps: 589 return: 3.0 avg return: 3.0\n",
            "epoch: 186 steps: 592 return: 3.0 avg return: 3.0\n",
            "epoch: 187 steps: 595 return: 3.0 avg return: 3.0\n",
            "epoch: 188 steps: 598 return: 3.0 avg return: 3.0\n",
            "epoch: 189 steps: 601 return: 3.0 avg return: 3.0\n",
            "epoch: 190 steps: 604 return: 3.0 avg return: 3.0\n",
            "epoch: 191 steps: 607 return: 3.0 avg return: 3.0\n",
            "epoch: 192 steps: 610 return: 3.0 avg return: 3.0\n",
            "epoch: 193 steps: 613 return: 3.0 avg return: 3.0\n",
            "epoch: 194 steps: 616 return: 3.0 avg return: 3.0\n",
            "epoch: 195 steps: 619 return: 3.0 avg return: 3.0\n",
            "epoch: 196 steps: 622 return: 3.0 avg return: 3.0\n",
            "epoch: 197 steps: 625 return: 3.0 avg return: 3.0\n",
            "epoch: 198 steps: 628 return: 3.0 avg return: 3.0\n",
            "epoch: 199 steps: 631 return: 3.0 avg return: 3.0\n",
            "epoch: 200 steps: 634 return: 3.0 avg return: 3.0\n",
            "epoch: 201 steps: 637 return: 3.0 avg return: 3.0\n",
            "epoch: 202 steps: 640 return: 3.0 avg return: 3.0\n",
            "epoch: 203 steps: 643 return: 3.0 avg return: 3.0\n",
            "epoch: 204 steps: 646 return: 3.0 avg return: 3.0\n",
            "epoch: 205 steps: 649 return: 3.0 avg return: 3.0\n",
            "epoch: 206 steps: 652 return: 3.0 avg return: 3.0\n",
            "epoch: 207 steps: 655 return: 3.0 avg return: 3.0\n",
            "epoch: 208 steps: 658 return: 3.0 avg return: 3.0\n",
            "epoch: 209 steps: 661 return: 3.0 avg return: 3.0\n",
            "epoch: 210 steps: 664 return: 3.0 avg return: 3.0\n",
            "epoch: 211 steps: 667 return: 3.0 avg return: 3.0\n",
            "epoch: 212 steps: 670 return: 3.0 avg return: 3.0\n",
            "epoch: 213 steps: 673 return: 3.0 avg return: 3.0\n",
            "epoch: 214 steps: 676 return: 3.0 avg return: 3.0\n",
            "epoch: 215 steps: 679 return: 3.0 avg return: 3.0\n",
            "epoch: 216 steps: 682 return: 3.0 avg return: 3.0\n",
            "epoch: 217 steps: 685 return: 3.0 avg return: 3.0\n",
            "epoch: 218 steps: 688 return: 3.0 avg return: 3.0\n",
            "epoch: 219 steps: 691 return: 3.0 avg return: 3.0\n",
            "epoch: 220 steps: 694 return: 3.0 avg return: 3.0\n",
            "epoch: 221 steps: 697 return: 3.0 avg return: 3.0\n",
            "epoch: 222 steps: 700 return: 3.0 avg return: 3.0\n",
            "epoch: 223 steps: 703 return: 3.0 avg return: 3.0\n",
            "epoch: 224 steps: 706 return: 3.0 avg return: 3.0\n",
            "epoch: 225 steps: 709 return: 3.0 avg return: 3.0\n",
            "epoch: 226 steps: 712 return: 3.0 avg return: 3.0\n",
            "epoch: 227 steps: 715 return: 3.0 avg return: 3.0\n",
            "epoch: 228 steps: 718 return: 3.0 avg return: 3.0\n",
            "epoch: 229 steps: 721 return: 3.0 avg return: 3.0\n",
            "epoch: 230 steps: 724 return: 3.0 avg return: 3.0\n",
            "epoch: 231 steps: 727 return: 3.0 avg return: 3.0\n",
            "epoch: 232 steps: 730 return: 3.0 avg return: 3.0\n",
            "epoch: 233 steps: 733 return: 3.0 avg return: 3.0\n",
            "epoch: 234 steps: 736 return: 3.0 avg return: 3.0\n",
            "epoch: 235 steps: 739 return: 3.0 avg return: 3.0\n",
            "epoch: 236 steps: 742 return: 3.0 avg return: 3.0\n",
            "epoch: 237 steps: 745 return: 3.0 avg return: 3.0\n",
            "epoch: 238 steps: 748 return: 3.0 avg return: 3.0\n",
            "epoch: 239 steps: 751 return: 3.0 avg return: 3.0\n",
            "epoch: 240 steps: 754 return: 3.0 avg return: 3.0\n",
            "epoch: 241 steps: 757 return: 3.0 avg return: 3.0\n",
            "epoch: 242 steps: 760 return: 3.0 avg return: 3.0\n",
            "epoch: 243 steps: 763 return: 3.0 avg return: 3.0\n",
            "epoch: 244 steps: 766 return: 3.0 avg return: 3.0\n",
            "epoch: 245 steps: 769 return: 3.0 avg return: 3.0\n",
            "epoch: 246 steps: 772 return: 3.0 avg return: 3.0\n",
            "epoch: 247 steps: 775 return: 3.0 avg return: 3.0\n",
            "epoch: 248 steps: 778 return: 3.0 avg return: 3.0\n",
            "epoch: 249 steps: 781 return: 3.0 avg return: 3.0\n",
            "epoch: 250 steps: 784 return: 3.0 avg return: 3.0\n",
            "epoch: 251 steps: 787 return: 3.0 avg return: 3.0\n",
            "epoch: 252 steps: 790 return: 3.0 avg return: 3.0\n",
            "epoch: 253 steps: 793 return: 3.0 avg return: 3.0\n",
            "epoch: 254 steps: 796 return: 3.0 avg return: 3.0\n",
            "epoch: 255 steps: 799 return: 3.0 avg return: 3.0\n",
            "epoch: 256 steps: 802 return: 3.0 avg return: 3.0\n",
            "epoch: 257 steps: 805 return: 3.0 avg return: 3.0\n",
            "epoch: 258 steps: 808 return: 3.0 avg return: 3.0\n",
            "epoch: 259 steps: 811 return: 3.0 avg return: 3.0\n",
            "epoch: 260 steps: 814 return: 3.0 avg return: 3.0\n",
            "epoch: 261 steps: 817 return: 3.0 avg return: 3.0\n",
            "epoch: 262 steps: 820 return: 3.0 avg return: 3.0\n",
            "epoch: 263 steps: 823 return: 3.0 avg return: 3.0\n",
            "epoch: 264 steps: 826 return: 3.0 avg return: 3.0\n",
            "epoch: 265 steps: 829 return: 3.0 avg return: 3.0\n",
            "epoch: 266 steps: 832 return: 3.0 avg return: 3.0\n",
            "epoch: 267 steps: 835 return: 3.0 avg return: 3.0\n",
            "epoch: 268 steps: 838 return: 3.0 avg return: 3.0\n",
            "epoch: 269 steps: 841 return: 3.0 avg return: 3.0\n",
            "epoch: 270 steps: 844 return: 3.0 avg return: 3.0\n",
            "epoch: 271 steps: 847 return: 3.0 avg return: 3.0\n",
            "epoch: 272 steps: 850 return: 3.0 avg return: 3.0\n",
            "epoch: 273 steps: 853 return: 3.0 avg return: 3.0\n",
            "epoch: 274 steps: 857 return: 4.0 avg return: 3.02\n",
            "epoch: 275 steps: 862 return: 5.0 avg return: 3.06\n",
            "epoch: 276 steps: 866 return: 4.0 avg return: 3.08\n",
            "epoch: 277 steps: 871 return: 5.0 avg return: 3.12\n",
            "epoch: 278 steps: 884 return: 13.0 avg return: 3.32\n",
            "epoch: 279 steps: 898 return: 14.0 avg return: 3.54\n",
            "epoch: 280 steps: 922 return: 24.0 avg return: 3.96\n",
            "epoch: 281 steps: 941 return: 19.0 avg return: 4.28\n",
            "epoch: 282 steps: 957 return: 16.0 avg return: 4.54\n",
            "epoch: 283 steps: 969 return: 12.0 avg return: 4.72\n",
            "epoch: 284 steps: 983 return: 14.0 avg return: 4.94\n",
            "epoch: 285 steps: 997 return: 14.0 avg return: 5.16\n",
            "epoch: 286 steps: 1008 return: 11.0 avg return: 5.32\n",
            "epoch: 287 steps: 1024 return: 16.0 avg return: 5.58\n",
            "epoch: 288 steps: 1039 return: 15.0 avg return: 5.82\n",
            "epoch: 289 steps: 1064 return: 25.0 avg return: 6.26\n",
            "epoch: 290 steps: 1122 return: 58.0 avg return: 7.36\n",
            "epoch: 291 steps: 1151 return: 29.0 avg return: 7.88\n",
            "epoch: 292 steps: 1181 return: 30.0 avg return: 8.42\n",
            "epoch: 293 steps: 1211 return: 30.0 avg return: 8.96\n",
            "epoch: 294 steps: 1246 return: 35.0 avg return: 9.6\n",
            "epoch: 295 steps: 1284 return: 38.0 avg return: 10.3\n",
            "epoch: 296 steps: 1319 return: 35.0 avg return: 10.94\n",
            "epoch: 297 steps: 1369 return: 50.0 avg return: 11.88\n",
            "epoch: 298 steps: 1419 return: 50.0 avg return: 12.82\n",
            "epoch: 299 steps: 1464 return: 45.0 avg return: 13.66\n",
            "epoch: 300 steps: 1507 return: 43.0 avg return: 14.46\n",
            "epoch: 301 steps: 1553 return: 46.0 avg return: 15.32\n",
            "epoch: 302 steps: 1598 return: 45.0 avg return: 16.16\n",
            "epoch: 303 steps: 1643 return: 45.0 avg return: 17.0\n",
            "epoch: 304 steps: 1686 return: 43.0 avg return: 17.8\n",
            "epoch: 305 steps: 1729 return: 43.0 avg return: 18.6\n",
            "epoch: 306 steps: 1774 return: 45.0 avg return: 19.44\n",
            "epoch: 307 steps: 1816 return: 42.0 avg return: 20.22\n",
            "epoch: 308 steps: 1857 return: 41.0 avg return: 20.98\n",
            "epoch: 309 steps: 1903 return: 46.0 avg return: 21.84\n",
            "epoch: 310 steps: 1947 return: 44.0 avg return: 22.66\n",
            "epoch: 311 steps: 1988 return: 41.0 avg return: 23.42\n",
            "epoch: 312 steps: 2035 return: 47.0 avg return: 24.3\n",
            "epoch: 313 steps: 2080 return: 45.0 avg return: 25.14\n",
            "epoch: 314 steps: 2124 return: 44.0 avg return: 25.96\n",
            "epoch: 315 steps: 2171 return: 47.0 avg return: 26.84\n",
            "epoch: 316 steps: 2215 return: 44.0 avg return: 27.66\n",
            "epoch: 317 steps: 2266 return: 51.0 avg return: 28.62\n",
            "epoch: 318 steps: 2313 return: 47.0 avg return: 29.5\n",
            "epoch: 319 steps: 2360 return: 47.0 avg return: 30.38\n",
            "epoch: 320 steps: 2408 return: 48.0 avg return: 31.28\n",
            "epoch: 321 steps: 2465 return: 57.0 avg return: 32.36\n",
            "epoch: 322 steps: 2512 return: 47.0 avg return: 33.24\n",
            "epoch: 323 steps: 2559 return: 47.0 avg return: 34.12\n",
            "epoch: 324 steps: 2604 return: 45.0 avg return: 34.94\n",
            "epoch: 325 steps: 2647 return: 43.0 avg return: 35.7\n",
            "epoch: 326 steps: 2695 return: 48.0 avg return: 36.58\n",
            "epoch: 327 steps: 2751 return: 56.0 avg return: 37.6\n",
            "epoch: 328 steps: 2795 return: 44.0 avg return: 38.22\n",
            "epoch: 329 steps: 2846 return: 51.0 avg return: 38.96\n",
            "epoch: 330 steps: 2889 return: 43.0 avg return: 39.34\n",
            "epoch: 331 steps: 2934 return: 45.0 avg return: 39.86\n",
            "epoch: 332 steps: 2979 return: 45.0 avg return: 40.44\n",
            "epoch: 333 steps: 3026 return: 47.0 avg return: 41.14\n",
            "epoch: 334 steps: 3070 return: 44.0 avg return: 41.74\n",
            "epoch: 335 steps: 3116 return: 46.0 avg return: 42.38\n",
            "epoch: 336 steps: 3164 return: 48.0 avg return: 43.12\n",
            "epoch: 337 steps: 3208 return: 44.0 avg return: 43.68\n",
            "epoch: 338 steps: 3255 return: 47.0 avg return: 44.32\n",
            "epoch: 339 steps: 3303 return: 48.0 avg return: 44.78\n",
            "epoch: 340 steps: 3346 return: 43.0 avg return: 44.48\n",
            "epoch: 341 steps: 3388 return: 42.0 avg return: 44.74\n",
            "epoch: 342 steps: 3431 return: 43.0 avg return: 45.0\n",
            "epoch: 343 steps: 3478 return: 47.0 avg return: 45.34\n",
            "epoch: 344 steps: 3521 return: 43.0 avg return: 45.5\n",
            "epoch: 345 steps: 3566 return: 45.0 avg return: 45.64\n",
            "epoch: 346 steps: 3616 return: 50.0 avg return: 45.94\n",
            "epoch: 347 steps: 3662 return: 46.0 avg return: 45.86\n",
            "epoch: 348 steps: 3706 return: 44.0 avg return: 45.74\n",
            "epoch: 349 steps: 3750 return: 44.0 avg return: 45.72\n",
            "epoch: 350 steps: 3798 return: 48.0 avg return: 45.82\n",
            "epoch: 351 steps: 3840 return: 42.0 avg return: 45.74\n",
            "epoch: 352 steps: 3882 return: 42.0 avg return: 45.68\n",
            "epoch: 353 steps: 3924 return: 42.0 avg return: 45.62\n",
            "epoch: 354 steps: 3967 return: 43.0 avg return: 45.62\n",
            "epoch: 355 steps: 4009 return: 42.0 avg return: 45.6\n",
            "epoch: 356 steps: 4052 return: 43.0 avg return: 45.56\n",
            "epoch: 357 steps: 4092 return: 40.0 avg return: 45.52\n",
            "epoch: 358 steps: 4140 return: 48.0 avg return: 45.66\n",
            "epoch: 359 steps: 4181 return: 41.0 avg return: 45.56\n",
            "epoch: 360 steps: 4222 return: 41.0 avg return: 45.5\n",
            "epoch: 361 steps: 4264 return: 42.0 avg return: 45.52\n",
            "epoch: 362 steps: 4305 return: 41.0 avg return: 45.4\n",
            "epoch: 363 steps: 4348 return: 43.0 avg return: 45.36\n",
            "epoch: 364 steps: 4391 return: 43.0 avg return: 45.34\n",
            "epoch: 365 steps: 4432 return: 41.0 avg return: 45.22\n",
            "epoch: 366 steps: 4475 return: 43.0 avg return: 45.2\n",
            "epoch: 367 steps: 4515 return: 40.0 avg return: 44.98\n",
            "epoch: 368 steps: 4558 return: 43.0 avg return: 44.9\n",
            "epoch: 369 steps: 4607 return: 49.0 avg return: 44.94\n",
            "epoch: 370 steps: 4648 return: 41.0 avg return: 44.8\n",
            "epoch: 371 steps: 4690 return: 42.0 avg return: 44.5\n",
            "epoch: 372 steps: 4732 return: 42.0 avg return: 44.4\n",
            "epoch: 373 steps: 4773 return: 41.0 avg return: 44.28\n",
            "epoch: 374 steps: 4813 return: 40.0 avg return: 44.18\n",
            "epoch: 375 steps: 4855 return: 42.0 avg return: 44.16\n",
            "epoch: 376 steps: 4902 return: 47.0 avg return: 44.14\n",
            "epoch: 377 steps: 4942 return: 40.0 avg return: 43.82\n",
            "epoch: 378 steps: 4984 return: 42.0 avg return: 43.78\n",
            "epoch: 379 steps: 5026 return: 42.0 avg return: 43.6\n",
            "epoch: 380 steps: 5067 return: 41.0 avg return: 43.56\n",
            "epoch: 381 steps: 5107 return: 40.0 avg return: 43.46\n",
            "epoch: 382 steps: 5151 return: 44.0 avg return: 43.44\n",
            "epoch: 383 steps: 5194 return: 43.0 avg return: 43.36\n",
            "epoch: 384 steps: 5235 return: 41.0 avg return: 43.3\n",
            "epoch: 385 steps: 5276 return: 41.0 avg return: 43.2\n",
            "epoch: 386 steps: 5315 return: 39.0 avg return: 43.02\n",
            "epoch: 387 steps: 5358 return: 43.0 avg return: 43.0\n",
            "epoch: 388 steps: 5398 return: 40.0 avg return: 42.86\n",
            "epoch: 389 steps: 5442 return: 44.0 avg return: 42.78\n",
            "epoch: 390 steps: 5481 return: 39.0 avg return: 42.7\n",
            "epoch: 391 steps: 5523 return: 42.0 avg return: 42.7\n",
            "epoch: 392 steps: 5564 return: 41.0 avg return: 42.66\n",
            "epoch: 393 steps: 5606 return: 42.0 avg return: 42.56\n",
            "epoch: 394 steps: 5649 return: 43.0 avg return: 42.56\n",
            "epoch: 395 steps: 5743 return: 94.0 avg return: 43.54\n",
            "epoch: 396 steps: 5782 return: 39.0 avg return: 43.32\n",
            "epoch: 397 steps: 5822 return: 40.0 avg return: 43.2\n",
            "epoch: 398 steps: 5862 return: 40.0 avg return: 43.12\n",
            "epoch: 399 steps: 5906 return: 44.0 avg return: 43.12\n",
            "epoch: 400 steps: 5950 return: 44.0 avg return: 43.04\n",
            "epoch: 401 steps: 5990 return: 40.0 avg return: 43.0\n",
            "epoch: 402 steps: 6034 return: 44.0 avg return: 43.04\n",
            "epoch: 403 steps: 6078 return: 44.0 avg return: 43.08\n",
            "epoch: 404 steps: 6117 return: 39.0 avg return: 43.0\n",
            "epoch: 405 steps: 6157 return: 40.0 avg return: 42.96\n",
            "epoch: 406 steps: 6198 return: 41.0 avg return: 42.92\n",
            "epoch: 407 steps: 6239 return: 41.0 avg return: 42.94\n",
            "epoch: 408 steps: 6277 return: 38.0 avg return: 42.74\n",
            "epoch: 409 steps: 6318 return: 41.0 avg return: 42.74\n",
            "epoch: 410 steps: 6360 return: 42.0 avg return: 42.76\n",
            "epoch: 411 steps: 6399 return: 39.0 avg return: 42.7\n",
            "epoch: 412 steps: 6438 return: 39.0 avg return: 42.66\n",
            "epoch: 413 steps: 6476 return: 38.0 avg return: 42.56\n",
            "epoch: 414 steps: 6514 return: 38.0 avg return: 42.46\n",
            "epoch: 415 steps: 6555 return: 41.0 avg return: 42.46\n",
            "epoch: 416 steps: 6594 return: 39.0 avg return: 42.38\n",
            "epoch: 417 steps: 6632 return: 38.0 avg return: 42.34\n",
            "epoch: 418 steps: 6669 return: 37.0 avg return: 42.22\n",
            "epoch: 419 steps: 6707 return: 38.0 avg return: 42.0\n",
            "epoch: 420 steps: 6746 return: 39.0 avg return: 41.96\n",
            "epoch: 421 steps: 6787 return: 41.0 avg return: 41.94\n",
            "epoch: 422 steps: 6825 return: 38.0 avg return: 41.86\n",
            "epoch: 423 steps: 6865 return: 40.0 avg return: 41.84\n",
            "epoch: 424 steps: 6902 return: 37.0 avg return: 41.78\n",
            "epoch: 425 steps: 6941 return: 39.0 avg return: 41.72\n",
            "epoch: 426 steps: 6978 return: 37.0 avg return: 41.52\n",
            "epoch: 427 steps: 7017 return: 39.0 avg return: 41.5\n",
            "epoch: 428 steps: 7054 return: 37.0 avg return: 41.4\n",
            "epoch: 429 steps: 7092 return: 38.0 avg return: 41.32\n",
            "epoch: 430 steps: 7130 return: 38.0 avg return: 41.26\n",
            "epoch: 431 steps: 7169 return: 39.0 avg return: 41.24\n",
            "epoch: 432 steps: 7205 return: 36.0 avg return: 41.08\n",
            "epoch: 433 steps: 7243 return: 38.0 avg return: 40.98\n",
            "epoch: 434 steps: 7283 return: 40.0 avg return: 40.96\n",
            "epoch: 435 steps: 7321 return: 38.0 avg return: 40.9\n",
            "epoch: 436 steps: 7360 return: 39.0 avg return: 40.9\n",
            "epoch: 437 steps: 7398 return: 38.0 avg return: 40.8\n",
            "epoch: 438 steps: 7437 return: 39.0 avg return: 40.78\n",
            "epoch: 439 steps: 7474 return: 37.0 avg return: 40.64\n",
            "epoch: 440 steps: 7512 return: 38.0 avg return: 40.62\n",
            "epoch: 441 steps: 7550 return: 38.0 avg return: 40.54\n",
            "epoch: 442 steps: 7588 return: 38.0 avg return: 40.48\n",
            "epoch: 443 steps: 7626 return: 38.0 avg return: 40.4\n",
            "epoch: 444 steps: 7665 return: 39.0 avg return: 40.32\n",
            "epoch: 445 steps: 7702 return: 37.0 avg return: 39.18\n",
            "epoch: 446 steps: 7740 return: 38.0 avg return: 39.16\n",
            "epoch: 447 steps: 7779 return: 39.0 avg return: 39.14\n",
            "epoch: 448 steps: 7818 return: 39.0 avg return: 39.12\n",
            "epoch: 449 steps: 7857 return: 39.0 avg return: 39.02\n",
            "epoch: 450 steps: 7894 return: 37.0 avg return: 38.88\n",
            "epoch: 451 steps: 7932 return: 38.0 avg return: 38.84\n",
            "epoch: 452 steps: 7969 return: 37.0 avg return: 38.7\n",
            "epoch: 453 steps: 8007 return: 38.0 avg return: 38.58\n",
            "epoch: 454 steps: 8045 return: 38.0 avg return: 38.56\n",
            "epoch: 455 steps: 8082 return: 37.0 avg return: 38.5\n",
            "epoch: 456 steps: 8120 return: 38.0 avg return: 38.44\n",
            "epoch: 457 steps: 8133 return: 13.0 avg return: 37.88\n",
            "epoch: 458 steps: 8173 return: 40.0 avg return: 37.92\n",
            "epoch: 459 steps: 8210 return: 37.0 avg return: 37.84\n",
            "epoch: 460 steps: 8247 return: 37.0 avg return: 37.74\n",
            "epoch: 461 steps: 8284 return: 37.0 avg return: 37.7\n",
            "epoch: 462 steps: 8323 return: 39.0 avg return: 37.7\n",
            "epoch: 463 steps: 8360 return: 37.0 avg return: 37.68\n",
            "epoch: 464 steps: 8397 return: 37.0 avg return: 37.66\n",
            "epoch: 465 steps: 8435 return: 38.0 avg return: 37.6\n",
            "epoch: 466 steps: 8473 return: 38.0 avg return: 37.58\n",
            "epoch: 467 steps: 8512 return: 39.0 avg return: 37.6\n",
            "epoch: 468 steps: 8550 return: 38.0 avg return: 37.62\n",
            "epoch: 469 steps: 8588 return: 38.0 avg return: 37.62\n",
            "epoch: 470 steps: 8627 return: 39.0 avg return: 37.62\n",
            "epoch: 471 steps: 8665 return: 38.0 avg return: 37.56\n",
            "epoch: 472 steps: 8702 return: 37.0 avg return: 37.54\n",
            "epoch: 473 steps: 8739 return: 37.0 avg return: 37.48\n",
            "epoch: 474 steps: 8778 return: 39.0 avg return: 37.52\n",
            "epoch: 475 steps: 8816 return: 38.0 avg return: 37.5\n",
            "epoch: 476 steps: 8854 return: 38.0 avg return: 37.52\n",
            "epoch: 477 steps: 8894 return: 40.0 avg return: 37.54\n",
            "epoch: 478 steps: 8933 return: 39.0 avg return: 37.58\n",
            "epoch: 479 steps: 8973 return: 40.0 avg return: 37.62\n",
            "epoch: 480 steps: 9012 return: 39.0 avg return: 37.64\n",
            "epoch: 481 steps: 9050 return: 38.0 avg return: 37.62\n",
            "epoch: 482 steps: 9090 return: 40.0 avg return: 37.7\n",
            "epoch: 483 steps: 9129 return: 39.0 avg return: 37.72\n",
            "epoch: 484 steps: 9168 return: 39.0 avg return: 37.7\n",
            "epoch: 485 steps: 9207 return: 39.0 avg return: 37.72\n",
            "epoch: 486 steps: 9244 return: 37.0 avg return: 37.68\n",
            "epoch: 487 steps: 9281 return: 37.0 avg return: 37.66\n",
            "epoch: 488 steps: 9319 return: 38.0 avg return: 37.64\n",
            "epoch: 489 steps: 9356 return: 37.0 avg return: 37.64\n",
            "epoch: 490 steps: 9395 return: 39.0 avg return: 37.66\n",
            "epoch: 491 steps: 9432 return: 37.0 avg return: 37.64\n",
            "epoch: 492 steps: 9469 return: 37.0 avg return: 37.62\n",
            "epoch: 493 steps: 9480 return: 11.0 avg return: 37.08\n",
            "epoch: 494 steps: 9518 return: 38.0 avg return: 37.06\n",
            "epoch: 495 steps: 9556 return: 38.0 avg return: 37.08\n",
            "epoch: 496 steps: 9594 return: 38.0 avg return: 37.08\n",
            "epoch: 497 steps: 9632 return: 38.0 avg return: 37.06\n",
            "epoch: 498 steps: 9669 return: 37.0 avg return: 37.02\n",
            "epoch: 499 steps: 9708 return: 39.0 avg return: 37.02\n",
            "epoch: 500 steps: 9746 return: 38.0 avg return: 37.04\n",
            "epoch: 501 steps: 9784 return: 38.0 avg return: 37.04\n",
            "epoch: 502 steps: 9824 return: 40.0 avg return: 37.1\n",
            "epoch: 503 steps: 9863 return: 39.0 avg return: 37.12\n",
            "epoch: 504 steps: 9900 return: 37.0 avg return: 37.1\n",
            "epoch: 505 steps: 9940 return: 40.0 avg return: 37.16\n",
            "epoch: 506 steps: 9973 return: 33.0 avg return: 37.06\n",
            "epoch: 507 steps: 10013 return: 40.0 avg return: 37.6\n",
            "epoch: 508 steps: 10052 return: 39.0 avg return: 37.58\n",
            "epoch: 509 steps: 10090 return: 38.0 avg return: 37.6\n",
            "epoch: 510 steps: 10129 return: 39.0 avg return: 37.64\n",
            "epoch: 511 steps: 10167 return: 38.0 avg return: 37.66\n",
            "epoch: 512 steps: 10207 return: 40.0 avg return: 37.68\n",
            "epoch: 513 steps: 10245 return: 38.0 avg return: 37.7\n",
            "epoch: 514 steps: 10285 return: 40.0 avg return: 37.76\n",
            "epoch: 515 steps: 10323 return: 38.0 avg return: 37.76\n",
            "epoch: 516 steps: 10332 return: 9.0 avg return: 37.18\n",
            "epoch: 517 steps: 10371 return: 39.0 avg return: 37.18\n",
            "epoch: 518 steps: 10410 return: 39.0 avg return: 37.2\n",
            "epoch: 519 steps: 10450 return: 40.0 avg return: 37.24\n",
            "epoch: 520 steps: 10489 return: 39.0 avg return: 37.24\n",
            "epoch: 521 steps: 10529 return: 40.0 avg return: 37.28\n",
            "epoch: 522 steps: 10570 return: 41.0 avg return: 37.36\n",
            "epoch: 523 steps: 10609 return: 39.0 avg return: 37.4\n",
            "epoch: 524 steps: 10648 return: 39.0 avg return: 37.4\n",
            "epoch: 525 steps: 10688 return: 40.0 avg return: 37.44\n",
            "epoch: 526 steps: 10726 return: 38.0 avg return: 37.44\n",
            "epoch: 527 steps: 10766 return: 40.0 avg return: 37.44\n",
            "epoch: 528 steps: 10804 return: 38.0 avg return: 37.42\n",
            "epoch: 529 steps: 10844 return: 40.0 avg return: 37.42\n",
            "epoch: 530 steps: 10882 return: 38.0 avg return: 37.4\n",
            "epoch: 531 steps: 10921 return: 39.0 avg return: 37.42\n",
            "epoch: 532 steps: 10961 return: 40.0 avg return: 37.42\n",
            "epoch: 533 steps: 11001 return: 40.0 avg return: 37.44\n",
            "epoch: 534 steps: 11040 return: 39.0 avg return: 37.44\n",
            "epoch: 535 steps: 11080 return: 40.0 avg return: 37.46\n",
            "epoch: 536 steps: 11120 return: 40.0 avg return: 37.52\n",
            "epoch: 537 steps: 11159 return: 39.0 avg return: 37.56\n",
            "epoch: 538 steps: 11198 return: 39.0 avg return: 37.58\n",
            "epoch: 539 steps: 11206 return: 8.0 avg return: 37.0\n",
            "epoch: 540 steps: 11245 return: 39.0 avg return: 37.0\n",
            "epoch: 541 steps: 11284 return: 39.0 avg return: 37.04\n",
            "epoch: 542 steps: 11324 return: 40.0 avg return: 37.1\n",
            "epoch: 543 steps: 11364 return: 40.0 avg return: 37.68\n",
            "epoch: 544 steps: 11404 return: 40.0 avg return: 37.72\n",
            "epoch: 545 steps: 11443 return: 39.0 avg return: 37.74\n",
            "epoch: 546 steps: 11482 return: 39.0 avg return: 37.76\n",
            "epoch: 547 steps: 11520 return: 38.0 avg return: 37.76\n",
            "epoch: 548 steps: 11558 return: 38.0 avg return: 37.78\n",
            "epoch: 549 steps: 11597 return: 39.0 avg return: 37.78\n",
            "epoch: 550 steps: 11637 return: 40.0 avg return: 37.82\n",
            "epoch: 551 steps: 11677 return: 40.0 avg return: 37.86\n",
            "epoch: 552 steps: 11716 return: 39.0 avg return: 37.84\n",
            "epoch: 553 steps: 11756 return: 40.0 avg return: 37.86\n",
            "epoch: 554 steps: 11796 return: 40.0 avg return: 37.92\n",
            "epoch: 555 steps: 11836 return: 40.0 avg return: 37.92\n",
            "epoch: 556 steps: 11875 return: 39.0 avg return: 38.04\n",
            "epoch: 557 steps: 11917 return: 42.0 avg return: 38.08\n",
            "epoch: 558 steps: 11958 return: 41.0 avg return: 38.12\n",
            "epoch: 559 steps: 11998 return: 40.0 avg return: 38.16\n",
            "epoch: 560 steps: 12038 return: 40.0 avg return: 38.18\n",
            "epoch: 561 steps: 12078 return: 40.0 avg return: 38.22\n",
            "epoch: 562 steps: 12117 return: 39.0 avg return: 38.2\n",
            "epoch: 563 steps: 12157 return: 40.0 avg return: 38.24\n",
            "epoch: 564 steps: 12197 return: 40.0 avg return: 38.24\n",
            "epoch: 565 steps: 12237 return: 40.0 avg return: 38.28\n",
            "epoch: 566 steps: 12277 return: 40.0 avg return: 38.9\n",
            "epoch: 567 steps: 12318 return: 41.0 avg return: 38.94\n",
            "epoch: 568 steps: 12359 return: 41.0 avg return: 38.98\n",
            "epoch: 569 steps: 12398 return: 39.0 avg return: 38.96\n",
            "epoch: 570 steps: 12439 return: 41.0 avg return: 39.0\n",
            "epoch: 571 steps: 12478 return: 39.0 avg return: 38.98\n",
            "epoch: 572 steps: 12519 return: 41.0 avg return: 38.98\n",
            "epoch: 573 steps: 12560 return: 41.0 avg return: 39.02\n",
            "epoch: 574 steps: 12602 return: 42.0 avg return: 39.08\n",
            "epoch: 575 steps: 12642 return: 40.0 avg return: 39.08\n",
            "epoch: 576 steps: 12684 return: 42.0 avg return: 39.16\n",
            "epoch: 577 steps: 12724 return: 40.0 avg return: 39.16\n",
            "epoch: 578 steps: 12765 return: 41.0 avg return: 39.22\n",
            "epoch: 579 steps: 12806 return: 41.0 avg return: 39.24\n",
            "epoch: 580 steps: 12848 return: 42.0 avg return: 39.32\n",
            "epoch: 581 steps: 12889 return: 41.0 avg return: 39.36\n",
            "epoch: 582 steps: 12929 return: 40.0 avg return: 39.36\n",
            "epoch: 583 steps: 12971 return: 42.0 avg return: 39.4\n",
            "epoch: 584 steps: 13010 return: 39.0 avg return: 39.4\n",
            "epoch: 585 steps: 13052 return: 42.0 avg return: 39.44\n",
            "epoch: 586 steps: 13092 return: 40.0 avg return: 39.44\n",
            "epoch: 587 steps: 13133 return: 41.0 avg return: 39.48\n",
            "epoch: 588 steps: 13174 return: 41.0 avg return: 39.52\n",
            "epoch: 589 steps: 13214 return: 40.0 avg return: 40.16\n",
            "epoch: 590 steps: 13256 return: 42.0 avg return: 40.22\n",
            "epoch: 591 steps: 13301 return: 45.0 avg return: 40.34\n",
            "epoch: 592 steps: 13343 return: 42.0 avg return: 40.38\n",
            "epoch: 593 steps: 13385 return: 42.0 avg return: 40.42\n",
            "epoch: 594 steps: 13428 return: 43.0 avg return: 40.48\n",
            "epoch: 595 steps: 13473 return: 45.0 avg return: 40.6\n",
            "epoch: 596 steps: 13517 return: 44.0 avg return: 40.7\n",
            "epoch: 597 steps: 13561 return: 44.0 avg return: 40.82\n",
            "epoch: 598 steps: 13606 return: 45.0 avg return: 40.96\n",
            "epoch: 599 steps: 13654 return: 48.0 avg return: 41.14\n",
            "epoch: 600 steps: 13701 return: 47.0 avg return: 41.28\n",
            "epoch: 601 steps: 13745 return: 44.0 avg return: 41.36\n",
            "epoch: 602 steps: 13795 return: 50.0 avg return: 41.58\n",
            "epoch: 603 steps: 13843 return: 48.0 avg return: 41.74\n",
            "epoch: 604 steps: 13884 return: 41.0 avg return: 41.76\n",
            "epoch: 605 steps: 13936 return: 52.0 avg return: 42.0\n",
            "epoch: 606 steps: 13984 return: 48.0 avg return: 42.18\n",
            "epoch: 607 steps: 14038 return: 54.0 avg return: 42.42\n",
            "epoch: 608 steps: 14118 return: 80.0 avg return: 43.2\n",
            "epoch: 609 steps: 14186 return: 68.0 avg return: 43.76\n",
            "epoch: 610 steps: 14263 return: 77.0 avg return: 44.5\n",
            "epoch: 611 steps: 14361 return: 98.0 avg return: 45.66\n",
            "epoch: 612 steps: 14425 return: 64.0 avg return: 46.16\n",
            "epoch: 613 steps: 14501 return: 76.0 avg return: 46.88\n",
            "epoch: 614 steps: 14540 return: 39.0 avg return: 46.86\n",
            "epoch: 615 steps: 14595 return: 55.0 avg return: 47.16\n",
            "epoch: 616 steps: 14637 return: 42.0 avg return: 47.2\n",
            "epoch: 617 steps: 14674 return: 37.0 avg return: 47.12\n",
            "epoch: 618 steps: 14710 return: 36.0 avg return: 47.02\n",
            "epoch: 619 steps: 14756 return: 46.0 avg return: 47.16\n",
            "epoch: 620 steps: 14801 return: 45.0 avg return: 47.24\n",
            "epoch: 621 steps: 14832 return: 31.0 avg return: 47.08\n",
            "epoch: 622 steps: 14871 return: 39.0 avg return: 47.04\n",
            "epoch: 623 steps: 14907 return: 36.0 avg return: 46.94\n",
            "epoch: 624 steps: 14964 return: 57.0 avg return: 47.24\n",
            "epoch: 625 steps: 15000 return: 36.0 avg return: 47.16\n",
            "epoch: 626 steps: 15040 return: 40.0 avg return: 47.12\n",
            "epoch: 627 steps: 15077 return: 37.0 avg return: 47.06\n",
            "epoch: 628 steps: 15175 return: 98.0 avg return: 48.2\n",
            "epoch: 629 steps: 15220 return: 45.0 avg return: 48.28\n",
            "epoch: 630 steps: 15255 return: 35.0 avg return: 48.14\n",
            "epoch: 631 steps: 15303 return: 48.0 avg return: 48.28\n",
            "epoch: 632 steps: 15359 return: 56.0 avg return: 48.6\n",
            "epoch: 633 steps: 15399 return: 40.0 avg return: 48.56\n",
            "epoch: 634 steps: 15465 return: 66.0 avg return: 49.1\n",
            "epoch: 635 steps: 15500 return: 35.0 avg return: 48.96\n",
            "epoch: 636 steps: 15532 return: 32.0 avg return: 48.8\n",
            "epoch: 637 steps: 15569 return: 37.0 avg return: 48.72\n",
            "epoch: 638 steps: 15603 return: 34.0 avg return: 48.58\n",
            "epoch: 639 steps: 15634 return: 31.0 avg return: 48.4\n",
            "epoch: 640 steps: 15664 return: 30.0 avg return: 48.16\n",
            "epoch: 641 steps: 15699 return: 35.0 avg return: 47.96\n",
            "epoch: 642 steps: 15732 return: 33.0 avg return: 47.78\n",
            "epoch: 643 steps: 15771 return: 39.0 avg return: 47.72\n",
            "epoch: 644 steps: 15808 return: 37.0 avg return: 47.6\n",
            "epoch: 645 steps: 15847 return: 39.0 avg return: 47.48\n",
            "epoch: 646 steps: 15882 return: 35.0 avg return: 47.3\n",
            "epoch: 647 steps: 15919 return: 37.0 avg return: 47.16\n",
            "epoch: 648 steps: 15955 return: 36.0 avg return: 46.98\n",
            "epoch: 649 steps: 15989 return: 34.0 avg return: 46.7\n",
            "epoch: 650 steps: 16023 return: 34.0 avg return: 46.44\n",
            "epoch: 651 steps: 16064 return: 41.0 avg return: 46.38\n",
            "epoch: 652 steps: 16094 return: 30.0 avg return: 45.98\n",
            "epoch: 653 steps: 16134 return: 40.0 avg return: 45.82\n",
            "epoch: 654 steps: 16176 return: 42.0 avg return: 45.84\n",
            "epoch: 655 steps: 16222 return: 46.0 avg return: 45.72\n",
            "epoch: 656 steps: 16253 return: 31.0 avg return: 45.38\n",
            "epoch: 657 steps: 16295 return: 42.0 avg return: 45.14\n",
            "epoch: 658 steps: 16329 return: 34.0 avg return: 44.22\n",
            "epoch: 659 steps: 16365 return: 36.0 avg return: 43.58\n",
            "epoch: 660 steps: 16396 return: 31.0 avg return: 42.66\n",
            "epoch: 661 steps: 16428 return: 32.0 avg return: 41.34\n",
            "epoch: 662 steps: 16461 return: 33.0 avg return: 40.72\n",
            "epoch: 663 steps: 16492 return: 31.0 avg return: 39.82\n",
            "epoch: 664 steps: 16524 return: 32.0 avg return: 39.68\n",
            "epoch: 665 steps: 16559 return: 35.0 avg return: 39.28\n",
            "epoch: 666 steps: 16594 return: 35.0 avg return: 39.14\n",
            "epoch: 667 steps: 16632 return: 38.0 avg return: 39.16\n",
            "epoch: 668 steps: 16669 return: 37.0 avg return: 39.18\n",
            "epoch: 669 steps: 16707 return: 38.0 avg return: 39.02\n",
            "epoch: 670 steps: 16743 return: 36.0 avg return: 38.84\n",
            "epoch: 671 steps: 16780 return: 37.0 avg return: 38.96\n",
            "epoch: 672 steps: 16815 return: 35.0 avg return: 38.88\n",
            "epoch: 673 steps: 16854 return: 39.0 avg return: 38.94\n",
            "epoch: 674 steps: 16889 return: 35.0 avg return: 38.5\n",
            "epoch: 675 steps: 16927 return: 38.0 avg return: 38.54\n",
            "epoch: 676 steps: 16962 return: 35.0 avg return: 38.44\n",
            "epoch: 677 steps: 17003 return: 41.0 avg return: 38.52\n",
            "epoch: 678 steps: 17042 return: 39.0 avg return: 37.34\n",
            "epoch: 679 steps: 17077 return: 35.0 avg return: 37.14\n",
            "epoch: 680 steps: 17115 return: 38.0 avg return: 37.2\n",
            "epoch: 681 steps: 17157 return: 42.0 avg return: 37.08\n",
            "epoch: 682 steps: 17199 return: 42.0 avg return: 36.8\n",
            "epoch: 683 steps: 17237 return: 38.0 avg return: 36.76\n",
            "epoch: 684 steps: 17281 return: 44.0 avg return: 36.32\n",
            "epoch: 685 steps: 17324 return: 43.0 avg return: 36.48\n",
            "epoch: 686 steps: 17369 return: 45.0 avg return: 36.74\n",
            "epoch: 687 steps: 17409 return: 40.0 avg return: 36.8\n",
            "epoch: 688 steps: 17452 return: 43.0 avg return: 36.98\n",
            "epoch: 689 steps: 17496 return: 44.0 avg return: 37.24\n",
            "epoch: 690 steps: 17540 return: 44.0 avg return: 37.52\n",
            "epoch: 691 steps: 17580 return: 40.0 avg return: 37.62\n",
            "epoch: 692 steps: 17634 return: 54.0 avg return: 38.04\n",
            "epoch: 693 steps: 17674 return: 40.0 avg return: 38.06\n",
            "epoch: 694 steps: 17716 return: 42.0 avg return: 38.16\n",
            "epoch: 695 steps: 17762 return: 46.0 avg return: 38.3\n",
            "epoch: 696 steps: 17807 return: 45.0 avg return: 38.5\n",
            "epoch: 697 steps: 17852 return: 45.0 avg return: 38.66\n",
            "epoch: 698 steps: 17893 return: 41.0 avg return: 38.76\n",
            "epoch: 699 steps: 17943 return: 50.0 avg return: 39.08\n",
            "epoch: 700 steps: 17989 return: 46.0 avg return: 39.32\n",
            "epoch: 701 steps: 18041 return: 52.0 avg return: 39.54\n",
            "epoch: 702 steps: 18084 return: 43.0 avg return: 39.8\n",
            "epoch: 703 steps: 18129 return: 45.0 avg return: 39.9\n",
            "epoch: 704 steps: 18179 return: 50.0 avg return: 40.06\n",
            "epoch: 705 steps: 18228 return: 49.0 avg return: 40.12\n",
            "epoch: 706 steps: 18276 return: 48.0 avg return: 40.46\n",
            "epoch: 707 steps: 18327 return: 51.0 avg return: 40.64\n",
            "epoch: 708 steps: 18374 return: 47.0 avg return: 40.9\n",
            "epoch: 709 steps: 18424 return: 50.0 avg return: 41.18\n",
            "epoch: 710 steps: 18472 return: 48.0 avg return: 41.52\n",
            "epoch: 711 steps: 18522 return: 50.0 avg return: 41.88\n",
            "epoch: 712 steps: 18570 return: 48.0 avg return: 42.18\n",
            "epoch: 713 steps: 18626 return: 56.0 avg return: 42.68\n",
            "epoch: 714 steps: 18682 return: 56.0 avg return: 43.16\n",
            "epoch: 715 steps: 18743 return: 61.0 avg return: 43.68\n",
            "epoch: 716 steps: 18789 return: 46.0 avg return: 43.9\n",
            "epoch: 717 steps: 18843 return: 54.0 avg return: 44.22\n",
            "epoch: 718 steps: 18898 return: 55.0 avg return: 44.58\n",
            "epoch: 719 steps: 18956 return: 58.0 avg return: 44.98\n",
            "epoch: 720 steps: 19012 return: 56.0 avg return: 45.38\n",
            "epoch: 721 steps: 19073 return: 61.0 avg return: 45.86\n",
            "epoch: 722 steps: 19127 return: 54.0 avg return: 46.24\n",
            "epoch: 723 steps: 19180 return: 53.0 avg return: 46.52\n",
            "epoch: 724 steps: 19241 return: 61.0 avg return: 47.04\n",
            "epoch: 725 steps: 19301 return: 60.0 avg return: 47.48\n",
            "epoch: 726 steps: 19363 return: 62.0 avg return: 48.02\n",
            "epoch: 727 steps: 19428 return: 65.0 avg return: 48.5\n",
            "epoch: 728 steps: 19512 return: 84.0 avg return: 49.4\n",
            "epoch: 729 steps: 19573 return: 61.0 avg return: 49.92\n",
            "epoch: 730 steps: 19652 return: 79.0 avg return: 50.74\n",
            "epoch: 731 steps: 19716 return: 64.0 avg return: 51.18\n",
            "epoch: 732 steps: 19787 return: 71.0 avg return: 51.76\n",
            "epoch: 733 steps: 19858 return: 71.0 avg return: 52.42\n",
            "epoch: 734 steps: 19925 return: 67.0 avg return: 52.88\n",
            "epoch: 735 steps: 19996 return: 71.0 avg return: 53.44\n",
            "epoch: 736 steps: 20069 return: 73.0 avg return: 54.0\n",
            "epoch: 737 steps: 20141 return: 72.0 avg return: 54.64\n",
            "epoch: 738 steps: 20229 return: 88.0 avg return: 55.54\n",
            "epoch: 739 steps: 20301 return: 72.0 avg return: 56.1\n",
            "epoch: 740 steps: 20376 return: 75.0 avg return: 56.72\n",
            "epoch: 741 steps: 20467 return: 91.0 avg return: 57.74\n",
            "epoch: 742 steps: 20544 return: 77.0 avg return: 58.2\n",
            "epoch: 743 steps: 20624 return: 80.0 avg return: 59.0\n",
            "epoch: 744 steps: 20702 return: 78.0 avg return: 59.72\n",
            "epoch: 745 steps: 20784 return: 82.0 avg return: 60.44\n",
            "epoch: 746 steps: 20860 return: 76.0 avg return: 61.06\n",
            "epoch: 747 steps: 20948 return: 88.0 avg return: 61.92\n",
            "epoch: 748 steps: 21035 return: 87.0 avg return: 62.84\n",
            "epoch: 749 steps: 21119 return: 84.0 avg return: 63.52\n",
            "epoch: 750 steps: 21206 return: 87.0 avg return: 64.34\n",
            "epoch: 751 steps: 21283 return: 77.0 avg return: 64.84\n",
            "epoch: 752 steps: 21367 return: 84.0 avg return: 65.66\n",
            "epoch: 753 steps: 21463 return: 96.0 avg return: 66.68\n",
            "epoch: 754 steps: 21565 return: 102.0 avg return: 67.72\n",
            "epoch: 755 steps: 21671 return: 106.0 avg return: 68.86\n",
            "epoch: 756 steps: 21793 return: 122.0 avg return: 70.34\n",
            "epoch: 757 steps: 21929 return: 136.0 avg return: 72.04\n",
            "epoch: 758 steps: 22051 return: 122.0 avg return: 73.54\n",
            "epoch: 759 steps: 22207 return: 156.0 avg return: 75.66\n",
            "epoch: 760 steps: 22381 return: 174.0 avg return: 78.18\n",
            "epoch: 761 steps: 22668 return: 287.0 avg return: 82.92\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5b55cc9142c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    269\u001b[0m                   critic_network_generator=partial(create_q_network, state_dim=env.observation_space.shape[0],\n\u001b[1;32m    270\u001b[0m                                                    action_dim=env.action_space.shape[0]))\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-5b55cc9142c8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, environment_steps, training_steps, pre_sampling_steps)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-5b55cc9142c8>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_policy_delay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}